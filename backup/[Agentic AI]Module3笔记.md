### 一、工具使用 Tool Use

流程：输入提示词——LLM决定是否调用工具箱中的工具——调用特定工具，工具输出结果作为上下文给LLM——LLM输出结果
对于更复杂的请求，模型也可以串联调用多个工具，形成工作流。

<img width="480" height="250" alt="Image" src="https://github.com/user-attachments/assets/77577779-8e6c-4cd0-afac-957fbd829c1a" />

工具调用赋予了LLM远超聊天的功能和执行能力！


### 二、工具调用方法
LLM本身并不会直接执行代码或调用函数，它被训练的核心能力是生成文本。 如何让LLM学会调用函数的过程，核心思想是模型不直接调用，而是“请求”调用。工具其实就是一些代码/函数。如今的主流语言模型都经过直接训练去使用工具，没有训练就必须得写提示词来告诉模型如何使用工具。

当前主流的 LLM 都经过了直接训练，能够原生地理解何时以及如何请求调用工具。
开发者不再需要像过去那样在提示词中硬编码特定的触发语法（如全大写的 “FUNCTION”），而是只需向 LLM 提供工具的描述和可用性，模型会自行决定何时调用。


### 三、工具调用语法 Tool Use Syntax
AI Suite 库：
这是一个开源库，由 Andrew Ng 及其团队开发。它提供了一种统一、简便的语法来调用多个不同的 LLM 提供商（如 OpenAI）。该库的核心功能之一是自动处理工具描述，极大简化了开发流程。

> 工作流程：
> 开发者定义函数： 编写一个带有清晰 docstring 的 Python 函数。
> AI Suite 自动化封装： 在调用 client.chat.completions.create 时，AI Suite 自动读取函数信息，生成标准的 JSON Schema。
> LLM 接收并决策： LLM 接收到包含所有可用工具描述的 Schema。它会根据当前的对话上下文和用户需求，决定是否需要调用某个工具。
> LLM 发出请求： 如果需要，LLM 会生成一个包含工具名称和所需参数的请求。
> 开发者执行工具： AI Suite 的客户端接收到 LLM 的请求后，会自动调用开发者定义的对应函数，并传入指定的参数。
> 结果返回与迭代： 函数执行的结果会被送回 LLM，LLM 可以基于此新信息继续思考，甚至发起下一次工具调用。整个过程最多可重复 max_turns 次。
> 最终响应： 当所有轮次结束或 LLM 决定不再调用工具时，它会生成最终的文本响应返回给用户。

如果提供的函数工具比较复杂，可能极大地增强LLM的能力。比如允许LLM调用一个强化学习框架来现场学东西，很有意思！（就像让LLM的执行大脑可以做凝聚人类知识的工程师，从而强很多）


### 四、一个特殊的工具 - 代码执行 Tool Use: Code Execution
代码执行（Code execution）是让大型语言模型（LLM）能够编写并运行代码，以解决用户提出的任务。这个工具是LLM具有更强的解决任务能力、更大的灵活性（比固定工具拓展性强得多）。 许多语言模型的训练者会专门优化模型，以确保其在应用中代码执行功能表现良好。

安全考量：安全的代码执行 (Secure Code Execution)

> 核心风险：在沙盒环境外运行由模型生成的任意代码是有风险的。
> 真实案例：
> 一位团队成员使用的高度智能体化代码执行器，曾错误地执行了 rm *.py 命令，删除了项目目录中的所有 Python 文件。
> 幸运的是，该成员有备份习惯，未造成实质损失。
> 最佳实践：
> 必须使用沙盒环境：这是保护系统、防止数据丢失或敏感数据泄露的最佳做法。
> 轻量级沙盒：推荐使用像 Docker 或 E2B 这样的轻量级沙盒环境，它们能有效隔离代码，降低损坏系统或环境的风险。
> 现实情况：尽管有风险，许多开发者仍会直接执行模型生成的代码而不做过多检查。但为了安全，应坚持使用沙盒。


### 五、MCP —— Model Context Protocol

定义：MCP（Model Context Protocol，模型上下文协议）是由 Entropy 提出的一个标准，旨在为大型语言模型（LLM）提供一种标准化的方式来访问外部工具和数据源。 目的：解决开发者在构建智能体式应用时，需要为每个应用重复编写代码来集成不同工具（如 Slack, GitHub, Google Drive 等）的痛点。 现状：该协议已被许多公司和开发者广泛采用，形成了一个活跃的生态系统。

MCP 的解决方案
引入共享服务器：MCP 提出了一种标准，允许应用程序通过一个共享的 MCP 服务器来访问工具和数据源。

<img width="800" height="400" alt="Image" src="https://github.com/user-attachments/assets/28333e37-25ad-4dc7-aa6f-14cde20300da" />



### 一些想学习的问题：
1.目前用的大模型软件都各自具备什么样的工具调用能力？比如web search好像大家都有，code execution好像也比较必要等。
2.大模型是怎么训练成原生支持工具调用的？
3.是否可以理解为：LLM就是一个核心的大脑，具有理解文字（或多模态信息）、发出调用指令的能力？然后加上工具才强得多？

